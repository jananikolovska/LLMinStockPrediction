{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bfd9bd7-1f61-4d80-8014-afd85c3ee666",
   "metadata": {},
   "source": [
    "# AI for stock market prediction: Using LLMs for TimeSeries Predictions (LLMTime implementation)\n",
    "\n",
    "Project by: Jana Nikolovska <br>\n",
    "Supervised by: Giacomo Frisoni, MSc <br><!--  -->\n",
    "Prof. Gianluca Moro, PhD <br>\n",
    "\n",
    "ALMA MATER STUDITORIUM - University of Bologna <br>\n",
    "November 2025\n",
    "\n",
    "---\n",
    "\n",
    "**Summary:** <br>\n",
    "In this project, I explore the use of Large Language Models (LLMs) for time series forecasting, focusing on the task of stock market prediction. The work was proposed and mentored by Prof. Gianluca Moro and Giacomo Frisoni at the University of Bologna.\n",
    "\n",
    "As a starting point, I used a provided notebook by my mentors. The notebook introduces the dataset (**historical S&P 500 data via [`yfinance`](https://pypi.org/project/yfinance/)**), a basic linear regression model, which I chose not to include in the final results, that served as an early benchmark and highlighted the underlying complexity of the forecasting problem and finally, the **\"Trading Protocol\"** ‚Äî a framework designed to evaluate forecasting performance through simulated trading strategies ‚Äîthat I extended upon to incorporate multiple strategy types and Monte Carlo-based robustness testing.\n",
    "\n",
    "On the chosen dataset, a traditional **statistical model ARIMA** and **LLM-based forecasting approaches** have been tested and evaluated. For the implementation, I followed the methodology described in [this paper](https://arxiv.org/pdf/2310.07820) and its [official implementation](https://github.com/ngruver/llmtime/tree/main). The code from the paper has been adapted and extended with additional functionality tailored to the specific requirements of my experiments.\n",
    "\n",
    "The problem was defined comparable to that of the referenced paper, particularly in terms of training and testing proportions. The task was defined such that, given 150 days of historical values, the objective was to predict the subsequent 29 days values following an autoregressive approach without direct access to ground truth during prediction.\n",
    "\n",
    "Unlike the provided baseline notebook, which operated directly on price levels, this project instead utilized log returns as the primary time-series input. This choice was motivated by findings from the exploratory data analysis, which indicated that the raw price series exhibited non-stationary behavior ‚Äî making a dificult target for predicting. Transforming the data into returns helped achieve approximate stationarity, giving a chance to  the models to capture relative changes more effectively.\n",
    "\n",
    "As mentioned earlier, both statistical and trading-based evaluation methods were used, with greater emphasis placed on the trading metrics (Trading Protocol), while the statistical ones were included primarily for completeness and exploratory insight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a151f5df-1781-4303-a6c0-d035404a653c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '4'\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import openai\n",
    "from data.serialize import SerializerSettings\n",
    "from models.darts import get_arima_predictions_data\n",
    "from models.llmtime import get_llmtime_predictions_data\n",
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "\n",
    "from src.utils import split_time_series\n",
    "from src.evaluation import *\n",
    "from src.visualizations import plot_predictions_vs_actual, plot_cumulative_returns_simulation, create_performance_summary_table\n",
    "from src.models.llmtime import get_autotuned_predictions_data\n",
    "\n",
    "# warnings.simplefilter('once', UserWarning)\n",
    "# warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff1769b4-d83d-4c5d-bd53-d57c8e11c93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"secrets/openai_key.txt\", \"r\") as file:\n",
    "    openai_api_key = file.read().strip()\n",
    "openai.api_key = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a98375f-337b-437a-b300-0e545f01d2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDS = {}\n",
    "RESULTS = []\n",
    "LAG = 12\n",
    "TRAIN_SIZE = 150\n",
    "PREDICTION_SIZE = 29\n",
    "RETURNS_PATH = os.path.join(\"data\",\"sp500_returns_modeling.csv\")\n",
    "DS_NAME = 'SP500_returns'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11052d5d-d4eb-487d-a0c3-5df30fda5eb7",
   "metadata": {},
   "source": [
    "## Model Setup and Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b548e08-212d-452d-867d-b1bf9373df6a",
   "metadata": {},
   "source": [
    "In this section, the models are introduced, and the key hyperparameters to be tuned and validated are defined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdfb26b-619d-4f59-b76b-1067b1d7d0a2",
   "metadata": {},
   "source": [
    "#### üìà **ARIMA**\n",
    "- Linear, statistical model  \n",
    "- Assumes stationarity  \n",
    "- Captures short-term autocorrelation  \n",
    "- Limited with nonlinear or regime changes  \n",
    "\n",
    "#### ü§ñ **ChatGPT (LLM-based)**\n",
    "- Transformer, deep learning approach  \n",
    "- Should perform better with nonlinear and complex dependencies  \n",
    "- No explicit statistical assumptions  \n",
    "- Less interpretable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e10db914-b5a8-4677-a094-3a5c8c33da79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Function adapted from: https://github.com/ngruver/llmtime\n",
    "    Original author(s): Nicholas Gruver et al.\n",
    "\"\"\"\n",
    "gpt4_hypers = dict(\n",
    "    model=\"gpt-4\",\n",
    "    alpha=0.3,\n",
    "    basic=True,\n",
    "    temp=1.0,\n",
    "    top_p=0.8,\n",
    "    settings=SerializerSettings(base=10, prec=3, signed=True, time_sep=', ', bit_sep='', minus_sign='-')\n",
    ")\n",
    "\n",
    "gpt3_hypers = dict(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    temp=0.7,\n",
    "    alpha=0.95,\n",
    "    beta=0.3,\n",
    "    basic=False,\n",
    "    settings=SerializerSettings(base=10, prec=3, signed=True, half_bin_correction=True)\n",
    ")\n",
    "arima_hypers = dict(p=[12,30], d=[1,2], q=[0])\n",
    "\n",
    "\"\"\"\n",
    "    Hyperparameters derived from Exploatory analysis of data\n",
    "\"\"\"\n",
    "# GPT-4 with volatility-aware settings (higher precision for extreme values)\n",
    "gpt4_volatility_aware = dict(\n",
    "    model=\"gpt-4\",\n",
    "    alpha=0.1,  # More aggressive scaling for volatility clustering detection\n",
    "    basic=False,  \n",
    "    temp=0.3,  # Lower temperature for more focused predictions during volatile periods\n",
    "    top_p=0.9,\n",
    "    settings=SerializerSettings(base=10, prec=4, signed=True, time_sep=', ', bit_sep='', minus_sign='-')\n",
    ")\n",
    "\n",
    "# GPT-3.5 with regime-change sensitivity\n",
    "gpt3_regime_sensitive = dict(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    temp=1.2,  # Higher creativity to capture regime changes\n",
    "    alpha=0.8,  # Medium scaling for robustness\n",
    "    beta=0.5,  # Higher beta for shift handling\n",
    "    basic=False,\n",
    "    settings=SerializerSettings(base=10, prec=3, signed=True, half_bin_correction=True, time_sep=', ')\n",
    ")\n",
    "\n",
    "# Conservative LLM configuration for stable periods\n",
    "gpt4_conservative = dict(\n",
    "    model=\"gpt-4\",\n",
    "    alpha=0.7,  # Conservative scaling\n",
    "    basic=True,\n",
    "    temp=0.1,  # Very low temperature for consistency\n",
    "    top_p=0.7,\n",
    "    settings=SerializerSettings(base=10, prec=2, signed=True, time_sep=', ', bit_sep='', minus_sign='-')\n",
    ")\n",
    "\n",
    "arima_short_term = dict(p=[1,2,3], d=[0,1], q=[0,1])  # For short-term dependencies\n",
    "arima_medium_term = dict(p=[5,7,12], d=[1], q=[1,2])  # Medium-term patterns\n",
    "arima_high_volatility = dict(p=[1,3,5], d=[1,2], q=[1,3])  # For volatile periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38df5e13-cf24-4ca6-bba6-a2d84e8d9651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# ARIMA Forecast\n",
    "# ======================================\n",
    "def arima_forecast(x, x_forecast, forecast_horizon: int = 5, hypers: dict = None) -> np.ndarray:\n",
    "    \"\"\"Forecast returns using ARIMA model\"\"\"\n",
    "    h = forecast_horizon\n",
    "\n",
    "    if hypers is None:\n",
    "       raise ValueError(\"Missing hypers\")\n",
    "   \n",
    "    preds = get_autotuned_predictions_data(\n",
    "        train=x,\n",
    "        test=x_forecast,\n",
    "        hypers=hypers,\n",
    "        num_samples=1,\n",
    "        get_predictions_fn=get_arima_predictions_data,\n",
    "        verbose=False,\n",
    "        parallel=False\n",
    "    )\n",
    "\n",
    "    fc = np.array(preds.get(\"median\", [0] * h), dtype=float)\n",
    "    return fc\n",
    "\n",
    "\n",
    "# ======================================\n",
    "# LLM Forecast\n",
    "# ======================================\n",
    "def llm_forecast(x, x_forecast, forecast_horizon: int = 5, hypers: dict = None) -> np.ndarray:\n",
    "    \"\"\"Forecast returns using ARIMA model\"\"\"\n",
    "    h = forecast_horizon\n",
    "\n",
    "    if hypers is None:\n",
    "       raise ValueError(\"Missing hypers\")\n",
    "   \n",
    "    preds = get_autotuned_predictions_data(\n",
    "        train=x,\n",
    "        test=x_forecast,\n",
    "        hypers=hypers,\n",
    "        num_samples=1,\n",
    "        get_predictions_fn=get_llmtime_predictions_data,\n",
    "        verbose=False,\n",
    "        parallel=False\n",
    "    )\n",
    "\n",
    "    fc = np.array(preds.get(\"median\", [0] * h), dtype=float)\n",
    "    return fc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3c422b-0447-4834-bafe-6a771d34bbf2",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3397a32",
   "metadata": {},
   "source": [
    "#### üíπ Trading Performance Evaluation\n",
    "\n",
    "This function evaluates trading performance by simulating investment decisions based on return predictions. It is an extention of the \"Trading Protocol\" introduced in the University notebook.  \n",
    "It supports multiple trading strategies:\n",
    "\n",
    "- **Threshold Strategy:** Buy when the predicted return exceeds a specified threshold  \n",
    "- **Relative Strategy:** Buy when the predicted return is above the median prediction  \n",
    "- **Top Quartile Strategy:** Buy only when the predicted return is in the top 25% of all predictions  \n",
    "\n",
    "The function calculates key metrics, including:\n",
    "\n",
    "- **üí∞ Total Return:** Overall percentage gain or loss across the forecast period  \n",
    "- **üéØ Directional Accuracy:** Proportion of times the model correctly predicted the direction of the return (up or down)  \n",
    "- **üìä Percentage of Profitable Trades:** Share of executed trades that resulted in a positive return  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53f769c4-b0c0-45d2-993c-e2d7e3bdf9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def returns_trading_performance_with_strategy(\n",
    "    predicted_returns,\n",
    "    actual_returns,\n",
    "    initial_capital=1000,\n",
    "    strategy=\"threshold\",\n",
    "    threshold=0.001,\n",
    "    verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Trading performance evaluation with multiple strategies.\n",
    "    Supports either a single series (1D) or multiple series (list-of-lists).\n",
    "\n",
    "    Args:\n",
    "        predicted_returns: 1D array/list OR list of 1D arrays/lists\n",
    "        actual_returns:    same shape structure as predicted_returns\n",
    "        initial_capital:   starting capital per series (if multiple series, applied per series)\n",
    "        strategy:          \"threshold\" | \"relative\" | \"top_quartile\"\n",
    "        threshold:         used only for \"threshold\" strategy\n",
    "        verbose:           print summary\n",
    "\n",
    "    Returns:\n",
    "        final_capital_agg, total_return_pct_agg, accuracy_agg, profitable_trades_pct_agg, trade_info\n",
    "          - Aggregates are averages across series if multiple series are provided.\n",
    "          - trade_info includes averages and a per-series breakdown.\n",
    "    \"\"\"\n",
    "\n",
    "    def _run_single_series(pred, act):\n",
    "        pred = np.array(pred)\n",
    "        act  = np.array(act)\n",
    "\n",
    "        # signals by strategy (computed per series)\n",
    "        if strategy == \"threshold\":\n",
    "            buy_signals = pred > threshold\n",
    "        elif strategy == \"relative\":\n",
    "            median_pred = np.median(pred)\n",
    "            buy_signals = pred > median_pred\n",
    "        elif strategy == \"top_quartile\":\n",
    "            quartile_75 = np.percentile(pred, 75)\n",
    "            buy_signals = pred >= quartile_75\n",
    "        else:\n",
    "            raise ValueError(\"Strategy must be 'threshold', 'relative', or 'top_quartile'\")\n",
    "\n",
    "        capital = initial_capital\n",
    "        trades = []\n",
    "\n",
    "        for i, (pred_ret, actual_ret) in enumerate(zip(pred, act)):\n",
    "            if buy_signals[i]:\n",
    "                capital += capital * actual_ret\n",
    "                trades.append(actual_ret)\n",
    "            else:\n",
    "                trades.append(0.0)\n",
    "\n",
    "        final_capital = float(capital)\n",
    "        total_return_pct = (final_capital - initial_capital) / initial_capital\n",
    "\n",
    "        # direction accuracy\n",
    "        accuracy = float(np.mean(np.sign(pred) == np.sign(act)))\n",
    "\n",
    "        # trades metrics\n",
    "        actual_trades = np.array(trades)[buy_signals]\n",
    "        if actual_trades.size > 0:\n",
    "            profitable_trades_pct = float(np.mean(actual_trades > 0))\n",
    "            avg_trade_return = float(np.mean(actual_trades))\n",
    "            num_trades = int(buy_signals.sum())\n",
    "        else:\n",
    "            profitable_trades_pct = 0.0\n",
    "            avg_trade_return = 0.0\n",
    "            num_trades = 0\n",
    "\n",
    "        return {\n",
    "            \"final_capital\": final_capital,\n",
    "            \"total_return_pct\": float(total_return_pct),\n",
    "            \"accuracy\": float(accuracy),\n",
    "            \"profitable_trades_pct\": float(profitable_trades_pct),\n",
    "            \"num_trades\": num_trades,\n",
    "            \"avg_trade_return\": float(avg_trade_return),\n",
    "        }\n",
    "\n",
    "    # Detect single-series vs multi-series\n",
    "    is_nested = isinstance(predicted_returns, (list, tuple)) and len(predicted_returns) > 0 and isinstance(predicted_returns[0], (list, tuple, np.ndarray))\n",
    "\n",
    "    if not is_nested:\n",
    "        # Single series path (keep original behavior)\n",
    "        res = _run_single_series(predicted_returns, actual_returns)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"=== Returns Trading Performance ===\")\n",
    "            print(f\"Strategy: {strategy.upper()}\")\n",
    "            if strategy == \"threshold\":\n",
    "                print(f\"Threshold: {threshold:.4f} ({threshold*100:.2f}%)\")\n",
    "            print(f\"Initial Capital: ${initial_capital:.2f}\")\n",
    "            print(f\"Final Capital: ${res['final_capital']:.2f}\")\n",
    "            print(f\"Total Return: {res['total_return_pct']:.2%}\")\n",
    "            print(f\"Direction Accuracy: {res['accuracy']:.2%}\")\n",
    "            print(f\"Number of Trades: {res['num_trades']}\")\n",
    "            print(f\"Profitable Trades: {res['profitable_trades_pct']:.2%}\")\n",
    "            if res['num_trades'] > 0:\n",
    "                print(f\"Average Trade Return: {res['avg_trade_return']:.4f} ({res['avg_trade_return']*100:.2f}%)\")\n",
    "\n",
    "        trade_info = {\n",
    "            \"num_trades\": res[\"num_trades\"],\n",
    "            \"avg_trade_return\": res[\"avg_trade_return\"],\n",
    "            \"strategy_used\": strategy,\n",
    "            \"threshold_used\": threshold if strategy == \"threshold\" else None\n",
    "        }\n",
    "\n",
    "        return (\n",
    "            res[\"final_capital\"],\n",
    "            res[\"total_return_pct\"],\n",
    "            res[\"accuracy\"],\n",
    "            res[\"profitable_trades_pct\"],\n",
    "            trade_info\n",
    "        )\n",
    "\n",
    "    # Multi-series path (list of lists)\n",
    "    if len(predicted_returns) != len(actual_returns):\n",
    "        raise ValueError(\"predicted_returns and actual_returns must have the same number of series\")\n",
    "\n",
    "    per_series_results = []\n",
    "    for pred_series, act_series in zip(predicted_returns, actual_returns):\n",
    "        if len(pred_series) != len(act_series):\n",
    "            raise ValueError(\"Each predicted/actual series pair must have the same length\")\n",
    "        per_series_results.append(_run_single_series(pred_series, act_series))\n",
    "\n",
    "    # Aggregate by averaging across series\n",
    "    final_capital_agg = float(np.mean([r[\"final_capital\"] for r in per_series_results]))\n",
    "    total_return_pct_agg = float(np.mean([r[\"total_return_pct\"] for r in per_series_results]))\n",
    "    accuracy_agg = float(np.mean([r[\"accuracy\"] for r in per_series_results]))\n",
    "    profitable_trades_pct_agg = float(np.mean([r[\"profitable_trades_pct\"] for r in per_series_results]))\n",
    "    avg_num_trades = float(np.mean([r[\"num_trades\"] for r in per_series_results]))\n",
    "    avg_trade_return = float(np.mean([r[\"avg_trade_return\"] for r in per_series_results]))\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"=== Returns Trading Performance (Multi-Series) ===\")\n",
    "        print(f\"Strategy: {strategy.upper()}  |  Series: {len(per_series_results)}\")\n",
    "        if strategy == \"threshold\":\n",
    "            print(f\"Threshold: {threshold:.4f} ({threshold*100:.2f}%)\")\n",
    "        print(f\"Initial Capital (per series): ${initial_capital:.2f}\")\n",
    "        print(f\"Avg Final Capital: ${final_capital_agg:.2f}\")\n",
    "        print(f\"Avg Total Return: {total_return_pct_agg:.2%}\")\n",
    "        print(f\"Avg Direction Accuracy: {accuracy_agg:.2%}\")\n",
    "        print(f\"Avg #Trades: {avg_num_trades:.2f}\")\n",
    "        print(f\"Avg Profitable Trades: {profitable_trades_pct_agg:.2%}\")\n",
    "        if avg_num_trades > 0:\n",
    "            print(f\"Avg Trade Return: {avg_trade_return:.4f} ({avg_trade_return*100:.2f}%)\")\n",
    "\n",
    "    trade_info = {\n",
    "        \"num_trades\": avg_num_trades,                # averaged for compatibility\n",
    "        \"avg_trade_return\": avg_trade_return,        # averaged for compatibility\n",
    "        \"strategy_used\": strategy,\n",
    "        \"threshold_used\": threshold if strategy == \"threshold\" else None,\n",
    "        \"per_series\": per_series_results             # detailed breakdown if you need it\n",
    "    }\n",
    "\n",
    "    return (\n",
    "        final_capital_agg,\n",
    "        total_return_pct_agg,\n",
    "        accuracy_agg,\n",
    "        profitable_trades_pct_agg,\n",
    "        trade_info\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e459616",
   "metadata": {},
   "source": [
    "#### ‚öôÔ∏è Prediction and Monte Carlo Trading Evaluation\n",
    "\n",
    "This function calculates **statistical and trading performance metrics** for each forecasting model.\n",
    "\n",
    "**Statistical Metrics**: <br>\n",
    "- **üìâ RMSE (Root Mean Squared Error):** Measures average magnitude of prediction errors  \n",
    "- **üìä MAE (Mean Absolute Error):** Captures the average absolute difference between predicted and actual returns  \n",
    "- **üìà R¬≤ (Coefficient of Determination):** Indicates how much of the variance in actual returns is explained by the model\n",
    "\n",
    "**Trading Protocol metrics**: <br>\n",
    "Then, for each of the trading strategies mentioned in the above function ‚Äî  \n",
    "runs **1,000 Monte Carlo simulations**, adding small Gaussian noise to the predictions to model uncertainty and averages the trading metrics, providing a robust estimate of model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77dc9855-c41b-466b-9bd7-128df700e3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_returns_with_trading(\n",
    "    train_data,\n",
    "    model_type: str = \"arima\",\n",
    "    forecast_horizon: int = 30,\n",
    "    hypers: dict = None,\n",
    "    initial_capital: float = 10_000,\n",
    "    strategies = (\"threshold\", \"relative\", \"top_quartile\"),\n",
    "    monte_carlo_runs: int = 1000,\n",
    "    noise_std: float = 0.001,      # 0.1% prediction noise per run\n",
    "    seed: int = 42,                # reproducibility\n",
    "    verbose: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Prediction + Monte Carlo trading evaluation BY STRATEGY.\n",
    "    Runs `monte_carlo_runs` simulations **for each strategy**, then reports/returns averages per strategy.\n",
    "\n",
    "    Args:\n",
    "        splits\n",
    "        model_type: \"arima\" or \"llm\"\n",
    "        forecast_horizon: number of periods to forecast\n",
    "        hypers: hyperparameters for the forecasting model\n",
    "        initial_capital: starting capital for trading simulation\n",
    "        strategies: iterable of strategy names to test (each run independently)\n",
    "        monte_carlo_runs: number of runs per strategy\n",
    "        noise_std: std-dev of Gaussian noise added to predictions each run\n",
    "        seed: RNG seed for reproducibility\n",
    "        verbose: print detailed output\n",
    "    Returns:\n",
    "        dict with:\n",
    "            - 'model': str\n",
    "            - 'statistical_metrics': dict\n",
    "            - 'by_strategy': {\n",
    "                strategy_name: {\n",
    "                    'summary': dict of averaged metrics,\n",
    "                    'runs': pd.DataFrame of all runs (per-run metrics)\n",
    "                }, ...\n",
    "              }\n",
    "            - 'predictions': np.ndarray (base, noiseless)\n",
    "            - 'actual': np.ndarray (true future)\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(f\" Model selected: {model_type.upper()}\")\n",
    "        print(f\" Using real S&P 500 returns data\")\n",
    "        print(f\" Monte Carlo: {monte_carlo_runs} runs per strategy\")\n",
    "        print(f\" Noise on predictions: N(0, {noise_std})\")\n",
    "\n",
    "    # Train-test split\n",
    "    data_history = list(s[0].values for s in train_data) \n",
    "    data_true_forecast = list(s[1].values for s in train_data)\n",
    "\n",
    "    # --- Make base predictions (noiseless baseline used as center) ---\n",
    "    if model_type.lower() == \"arima\":\n",
    "        preds_base = arima_forecast(data_history,data_true_forecast, forecast_horizon=forecast_horizon, hypers=hypers)\n",
    "    elif model_type.lower() == \"llm\":\n",
    "        preds_base = llm_forecast(data_history, data_true_forecast, forecast_horizon=forecast_horizon, hypers=hypers)\n",
    "    else:\n",
    "        raise ValueError(\"model_type must be 'arima' or 'llm'\")\n",
    "\n",
    "    # --- Standard metrics ONCE (noiseless) ---\n",
    "    true_vals = data_true_forecast\n",
    "\n",
    "    metrics = calculate_metrics(true_vals, preds_base)\n",
    "\n",
    "    print(f\"\\n ===== {model_type.upper()} Statistical Metrics (noiseless) =====\")\n",
    "    print(f\"RMSE: {metrics['RMSE']:.6f}\")\n",
    "    print(f\"MAE: {metrics['MAE']:.6f}\")\n",
    "    print(f\"R¬≤: {metrics['R2']:.4f}\")\n",
    "\n",
    "    # --- Monte Carlo BY STRATEGY ---\n",
    "    rng = np.random.default_rng(seed)\n",
    "    by_strategy = {}\n",
    "\n",
    "    for strategy in strategies:\n",
    "        print(f\"\\n ===== Strategy: {strategy} ‚Äî {monte_carlo_runs} runs =====\")\n",
    "\n",
    "        run_records = []\n",
    "        for _ in range(monte_carlo_runs):\n",
    "            # Add Gaussian noise to base predictions to simulate forecast uncertainty\n",
    "            noisy_preds = [\n",
    "                np.array(p) + rng.normal(0.0, noise_std, size=len(p))\n",
    "                for p in preds_base\n",
    "            ]\n",
    "\n",
    "\n",
    "            final_capital, total_return, accuracy, profitable_pct, trade_info = \\\n",
    "                returns_trading_performance_with_strategy(\n",
    "                    predicted_returns=noisy_preds,\n",
    "                    actual_returns=true_vals,\n",
    "                    initial_capital=initial_capital,\n",
    "                    strategy=strategy,\n",
    "                    threshold=0.0005,   # 0.05%\n",
    "                    verbose=False\n",
    "                )\n",
    "\n",
    "            run_records.append({\n",
    "                \"final_capital\": final_capital,\n",
    "                \"total_return\": total_return,\n",
    "                \"directional_acc\": accuracy,\n",
    "                \"profitable_pct\": profitable_pct,\n",
    "                \"num_trades\": trade_info.get(\"num_trades\", np.nan),\n",
    "                \"avg_trade_return\": trade_info.get(\"avg_trade_return\", np.nan),\n",
    "            })\n",
    "\n",
    "        df_runs = pd.DataFrame(run_records)\n",
    "\n",
    "        # Averages & basic dispersion\n",
    "        summary = {\n",
    "            \"avg_final_capital\": float(df_runs[\"final_capital\"].mean()),\n",
    "            \"std_final_capital\": float(df_runs[\"final_capital\"].std(ddof=1)),\n",
    "            \"avg_total_return\": float(df_runs[\"total_return\"].mean()),\n",
    "            \"std_total_return\": float(df_runs[\"total_return\"].std(ddof=1)),\n",
    "            \"avg_directional_acc\": float(df_runs[\"directional_acc\"].mean()),\n",
    "            \"avg_profitable_pct\": float(df_runs[\"profitable_pct\"].mean()),\n",
    "            \"avg_num_trades\": float(df_runs[\"num_trades\"].mean()),\n",
    "            \"avg_trade_return\": float(df_runs[\"avg_trade_return\"].mean()),\n",
    "            # a few risk percentiles\n",
    "            \"p05_total_return\": float(df_runs[\"total_return\"].quantile(0.05)),\n",
    "            \"p50_total_return\": float(df_runs[\"total_return\"].quantile(0.50)),\n",
    "            \"p95_total_return\": float(df_runs[\"total_return\"].quantile(0.95)),\n",
    "        }\n",
    "\n",
    "        \n",
    "        print(f\" Average Total Return: {summary['avg_total_return']:.2%} \"\n",
    "                  f\"(¬± {summary['std_total_return']:.2%}, p05 {summary['p05_total_return']:.2%}, \"\n",
    "                  f\"median {summary['p50_total_return']:.2%}, p95 {summary['p95_total_return']:.2%})\")\n",
    "        print(f\" Average Directional Accuracy: {summary['avg_directional_acc']:.2%}\")\n",
    "        print(f\" Average Profitable Trades: {summary['avg_profitable_pct']:.2%}\")\n",
    "        print(f\" Average Final Capital: ${summary['avg_final_capital']:.2f} \"\n",
    "                  f\"(¬± ${summary['std_final_capital']:.2f})\")\n",
    "        print(f\" Average #Trades: {summary['avg_num_trades']:.2f} | \"\n",
    "                  f\"Avg Trade Return: {summary['avg_trade_return']:.4%}\")\n",
    "\n",
    "        by_strategy[strategy] = {\n",
    "            \"summary\": summary,\n",
    "            \"runs\": df_runs\n",
    "        }\n",
    "\n",
    "    results = {\n",
    "        \"model\": model_type.upper(),\n",
    "        \"statistical_metrics\": metrics,\n",
    "        \"by_strategy\": by_strategy,\n",
    "        \"predictions\": preds_base,\n",
    "        \"actual\": true_vals\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d59ee3",
   "metadata": {},
   "source": [
    "## Running the Models and Analyzing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30366213-57df-4f46-bfc1-f30cb32a937a",
   "metadata": {},
   "source": [
    "In this section, we test and compare the three forecasting models. Each model is explored across different **subgroups of hyperparameter configurations** and chosen the **optimal hyperparameters** for each of them. Once the best configurations are determined, we apply the **evaluation framework** previously introduced to measure both  statistical accuracy and trading performance under the defined strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8b099c-3374-4634-a632-fb1a4b191d77",
   "metadata": {},
   "source": [
    "#### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81ce5b45-04a5-4260-af4f-0049fe3bea29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Loading returns dataset...\n",
      "Dataset shape: (2890, 8)\n",
      "Date range: 0 to 2889\n",
      "\n",
      "First few returns:\n",
      "                        date   returns        price        volume  \\\n",
      "0  2001-02-01 00:00:00-05:00  0.005461  1373.469971  1.118800e+09   \n",
      "1  2001-02-02 00:00:00-05:00 -0.017474  1349.469971  1.048400e+09   \n",
      "2  2001-02-03 00:00:00-05:00  0.001196  1351.083333  1.036600e+09   \n",
      "3  2001-02-04 00:00:00-05:00  0.001194  1352.696696  1.024800e+09   \n",
      "4  2001-02-05 00:00:00-05:00  0.001193  1354.310059  1.013000e+09   \n",
      "\n",
      "   rolling_volatility  returns_lag1  returns_lag2  returns_lag3  \n",
      "0            0.185403     -0.005620      0.007008      0.002258  \n",
      "1            0.128971      0.005461     -0.005620      0.007008  \n",
      "2            0.124988     -0.017474      0.005461     -0.005620  \n",
      "3            0.095957      0.001196     -0.017474      0.005461  \n",
      "4            0.095767      0.001194      0.001196     -0.017474  \n",
      "============================================================\n",
      " üß©Created 94 train-test splits for returns forecasting\n",
      "Each split - Train size: 150, Test size: 29\n",
      "\n",
      " Sample split structure:\n",
      "Train data (last 5 values):\n",
      "145   -0.001510\n",
      "146   -0.004676\n",
      "147    0.012493\n",
      "148   -0.001484\n",
      "149    0.003360\n",
      "Name: returns, dtype: float64\n",
      "<class 'pandas.core.series.Series'>\n",
      "\n",
      "Test data (first 5 values):\n",
      "150    0.003348\n",
      "151    0.003337\n",
      "152   -0.001836\n",
      "153   -0.006161\n",
      "154   -0.006199\n",
      "Name: returns, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "# Load returns data (stationary dataset from EDA)\n",
    "print(\"‚öôÔ∏è Loading returns dataset...\")\n",
    "returns_data = pd.read_csv(RETURNS_PATH)\n",
    "\n",
    "print(f\"Dataset shape: {returns_data.shape}\")\n",
    "print(f\"Date range: {returns_data.index.min()} to {returns_data.index.max()}\")\n",
    "print(\"\\nFirst few returns:\")\n",
    "print(returns_data.head())\n",
    "\n",
    "# Create splits for returns forecasting\n",
    "returns_series = returns_data['returns']\n",
    "splits = split_time_series(returns_series, TRAIN_SIZE, PREDICTION_SIZE)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\" üß©Created {len(splits)} train-test splits for returns forecasting\")\n",
    "print(f\"Each split - Train size: {TRAIN_SIZE}, Test size: {PREDICTION_SIZE}\")\n",
    "print(\"\\n Sample split structure:\")\n",
    "print(\"Train data (last 5 values):\")\n",
    "print(splits[0][0].tail())\n",
    "print(type(splits[0][0]))\n",
    "print(\"\\nTest data (first 5 values):\")\n",
    "print(splits[0][1].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f36190-7c5e-4233-b5ea-ac6aaac5f5b0",
   "metadata": {},
   "source": [
    "#### Running the Models and Obtaining Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "885075cf-a711-4ffe-b575-1746150d6c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Initial Capital: $10,000\n",
      " Forecast Horizon: 29 days\n"
     ]
    }
   ],
   "source": [
    "FORECAST_HORIZON = PREDICTION_SIZE\n",
    "INITIAL_CAPITAL = 10000  # $10,000 starting capital\n",
    "\n",
    "print(f\" Initial Capital: ${INITIAL_CAPITAL:,}\")\n",
    "print(f\" Forecast Horizon: {FORECAST_HORIZON} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d00ee5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TESTING ARIMA MODEL\n",
      "==================================================\n",
      "üßÆ Model: ARIMA\n",
      "Starting hyperparameter tuning over 4 configurations...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "700ad5e802794043a81141c2e678096c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Hyperparameter search:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling with best hyper... defaultdict(<class 'dict'>, {'p': 12, 'd': 1, 'q': 0}) \n",
      " with NLL -3.251371\n",
      "\n",
      " ===== ARIMA Statistical Metrics (noiseless) =====\n",
      "RMSE: 0.008833\n",
      "MAE: 0.006583\n",
      "R¬≤: -0.1744\n",
      "\n",
      " ===== Strategy: threshold ‚Äî 1000 runs =====\n",
      " Average Total Return: -0.39% (¬± 0.14%, p05 -0.62%, median -0.39%, p95 -0.16%)\n",
      " Average Directional Accuracy: 49.03%\n",
      " Average Profitable Trades: 46.05%\n",
      " Average Final Capital: $9960.77 (¬± $13.97)\n",
      " Average #Trades: 13.45 | Avg Trade Return: -0.0399%\n",
      "\n",
      " ===== Strategy: relative ‚Äî 1000 runs =====\n",
      " Average Total Return: -0.53% (¬± 0.20%, p05 -0.87%, median -0.53%, p95 -0.21%)\n",
      " Average Directional Accuracy: 49.01%\n",
      " Average Profitable Trades: 50.27%\n",
      " Average Final Capital: $9947.15 (¬± $20.06)\n",
      " Average #Trades: 14.00 | Avg Trade Return: -0.0373%\n",
      "\n",
      " ===== Strategy: top_quartile ‚Äî 1000 runs =====\n",
      " Average Total Return: -0.52% (¬± 0.18%, p05 -0.82%, median -0.52%, p95 -0.23%)\n",
      " Average Directional Accuracy: 49.02%\n",
      " Average Profitable Trades: 49.25%\n",
      " Average Final Capital: $9948.04 (¬± $18.16)\n",
      " Average #Trades: 8.00 | Avg Trade Return: -0.0653%\n",
      "========================================\n",
      "üßÆ Model: ARIMA Short-Term\n",
      "Starting hyperparameter tuning over 12 configurations...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "515cebe5421744df9e67a75b3f2decb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Hyperparameter search:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling with best hyper... defaultdict(<class 'dict'>, {'p': 1, 'd': 1, 'q': 1}) \n",
      " with NLL -3.390996\n",
      "\n",
      " ===== ARIMA Statistical Metrics (noiseless) =====\n",
      "RMSE: 0.008332\n",
      "MAE: 0.006028\n",
      "R¬≤: -0.0404\n",
      "\n",
      " ===== Strategy: threshold ‚Äî 1000 runs =====\n",
      " Average Total Return: -0.01% (¬± 0.19%, p05 -0.32%, median -0.01%, p95 0.30%)\n",
      " Average Directional Accuracy: 50.89%\n",
      " Average Profitable Trades: 49.04%\n",
      " Average Final Capital: $9999.20 (¬± $18.62)\n",
      " Average #Trades: 10.05 | Avg Trade Return: -0.0083%\n",
      "\n",
      " ===== Strategy: relative ‚Äî 1000 runs =====\n",
      " Average Total Return: -0.07% (¬± 0.27%, p05 -0.50%, median -0.07%, p95 0.37%)\n",
      " Average Directional Accuracy: 50.83%\n",
      " Average Profitable Trades: 52.01%\n",
      " Average Final Capital: $9993.03 (¬± $26.66)\n",
      " Average #Trades: 14.00 | Avg Trade Return: -0.0046%\n",
      "\n",
      " ===== Strategy: top_quartile ‚Äî 1000 runs =====\n",
      " Average Total Return: -0.03% (¬± 0.26%, p05 -0.45%, median -0.03%, p95 0.39%)\n",
      " Average Directional Accuracy: 50.85%\n",
      " Average Profitable Trades: 52.11%\n",
      " Average Final Capital: $9996.83 (¬± $25.63)\n",
      " Average #Trades: 8.00 | Avg Trade Return: -0.0038%\n",
      "========================================\n",
      "üßÆ Model: ARIMA Medium-Term\n",
      "Starting hyperparameter tuning over 6 configurations...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e987686e85194effb14ea64930e19610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Hyperparameter search:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling with best hyper... defaultdict(<class 'dict'>, {'p': 5, 'd': 1, 'q': 1}) \n",
      " with NLL -3.363400\n",
      "\n",
      " ===== ARIMA Statistical Metrics (noiseless) =====\n",
      "RMSE: 0.008344\n",
      "MAE: 0.006047\n",
      "R¬≤: -0.0427\n",
      "\n",
      " ===== Strategy: threshold ‚Äî 1000 runs =====\n",
      " Average Total Return: 0.04% (¬± 0.19%, p05 -0.26%, median 0.04%, p95 0.36%)\n",
      " Average Directional Accuracy: 50.73%\n",
      " Average Profitable Trades: 50.73%\n",
      " Average Final Capital: $10004.09 (¬± $18.84)\n",
      " Average #Trades: 10.28 | Avg Trade Return: -0.0073%\n",
      "\n",
      " ===== Strategy: relative ‚Äî 1000 runs =====\n",
      " Average Total Return: 0.03% (¬± 0.26%, p05 -0.40%, median 0.03%, p95 0.44%)\n",
      " Average Directional Accuracy: 50.66%\n",
      " Average Profitable Trades: 51.85%\n",
      " Average Final Capital: $10002.57 (¬± $25.54)\n",
      " Average #Trades: 14.00 | Avg Trade Return: 0.0022%\n",
      "\n",
      " ===== Strategy: top_quartile ‚Äî 1000 runs =====\n",
      " Average Total Return: 0.05% (¬± 0.23%, p05 -0.32%, median 0.06%, p95 0.42%)\n",
      " Average Directional Accuracy: 50.67%\n",
      " Average Profitable Trades: 51.85%\n",
      " Average Final Capital: $10005.11 (¬± $23.31)\n",
      " Average #Trades: 8.00 | Avg Trade Return: 0.0066%\n",
      "========================================\n",
      "üßÆ Model: ARIMA High-Volatility\n",
      "Starting hyperparameter tuning over 12 configurations...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9007ae0dfe0c45c29ffa653f18946696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Hyperparameter search:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling with best hyper... defaultdict(<class 'dict'>, {'p': 1, 'd': 1, 'q': 1}) \n",
      " with NLL -3.390996\n",
      "\n",
      " ===== ARIMA Statistical Metrics (noiseless) =====\n",
      "RMSE: 0.008332\n",
      "MAE: 0.006028\n",
      "R¬≤: -0.0404\n",
      "\n",
      " ===== Strategy: threshold ‚Äî 1000 runs =====\n",
      " Average Total Return: -0.01% (¬± 0.19%, p05 -0.32%, median -0.01%, p95 0.30%)\n",
      " Average Directional Accuracy: 50.89%\n",
      " Average Profitable Trades: 49.04%\n",
      " Average Final Capital: $9999.20 (¬± $18.62)\n",
      " Average #Trades: 10.05 | Avg Trade Return: -0.0083%\n",
      "\n",
      " ===== Strategy: relative ‚Äî 1000 runs =====\n",
      " Average Total Return: -0.07% (¬± 0.27%, p05 -0.50%, median -0.07%, p95 0.37%)\n",
      " Average Directional Accuracy: 50.83%\n",
      " Average Profitable Trades: 52.01%\n",
      " Average Final Capital: $9993.03 (¬± $26.66)\n",
      " Average #Trades: 14.00 | Avg Trade Return: -0.0046%\n",
      "\n",
      " ===== Strategy: top_quartile ‚Äî 1000 runs =====\n",
      " Average Total Return: -0.03% (¬± 0.26%, p05 -0.45%, median -0.03%, p95 0.39%)\n",
      " Average Directional Accuracy: 50.85%\n",
      " Average Profitable Trades: 52.11%\n",
      " Average Final Capital: $9996.83 (¬± $25.63)\n",
      " Average #Trades: 8.00 | Avg Trade Return: -0.0038%\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# Test ARIMA Model\n",
    "# ======================================\n",
    "\n",
    "print(\"\\n TESTING ARIMA MODEL\")\n",
    "print(\"=\" * 50)\n",
    "arima_models = {'ARIMA': arima_hypers,\n",
    "                'ARIMA Short-Term': arima_short_term,\n",
    "                'ARIMA Medium-Term': arima_medium_term,\n",
    "                'ARIMA High-Volatility': arima_high_volatility}\n",
    "all_arima_results = dict()\n",
    "for model_name, params in arima_models.items():\n",
    "    print(f\"üßÆ Model: {model_name}\")\n",
    "    all_arima_results[model_name] = predict_returns_with_trading(\n",
    "        splits, \n",
    "        model_type=\"arima\", \n",
    "        forecast_horizon=FORECAST_HORIZON,\n",
    "        initial_capital=INITIAL_CAPITAL,\n",
    "        hypers = params,\n",
    "        verbose = False\n",
    "    )\n",
    "    print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40f8b57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TESTING GPT-3.5 MODEL\n",
      "==================================================\n",
      "üßÆ Model: LLMTime GPT-3.5\n",
      "Starting hyperparameter tuning over 1 configurations...\n",
      "Sampling with best hyper... defaultdict(<class 'dict'>, {'model': 'gpt-3.5-turbo-instruct', 'temp': 0.7, 'alpha': 0.95, 'beta': 0.3, 'basic': False, 'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=' ,', bit_sep=' ', plus_sign='', minus_sign=' -', half_bin_correction=True, decimal_point='', missing_str=' Nan')}) \n",
      " with NLL inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 94/94 [03:41<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prediction too short 28 < 29, padded with last value\n",
      "\n",
      " ===== LLM Statistical Metrics (noiseless) =====\n",
      "RMSE: 0.013524\n",
      "MAE: 0.010103\n",
      "R¬≤: -3.2078\n",
      "\n",
      " ===== Strategy: threshold ‚Äî 1000 runs =====\n",
      " Average Total Return: -0.12% (¬± 0.08%, p05 -0.25%, median -0.12%, p95 0.01%)\n",
      " Average Directional Accuracy: 51.63%\n",
      " Average Profitable Trades: 54.22%\n",
      " Average Final Capital: $9987.89 (¬± $8.11)\n",
      " Average #Trades: 15.19 | Avg Trade Return: 0.0151%\n",
      "\n",
      " ===== Strategy: relative ‚Äî 1000 runs =====\n",
      " Average Total Return: 0.08% (¬± 0.10%, p05 -0.09%, median 0.08%, p95 0.25%)\n",
      " Average Directional Accuracy: 51.62%\n",
      " Average Profitable Trades: 53.00%\n",
      " Average Final Capital: $10007.63 (¬± $10.43)\n",
      " Average #Trades: 14.00 | Avg Trade Return: 0.0070%\n",
      "\n",
      " ===== Strategy: top_quartile ‚Äî 1000 runs =====\n",
      " Average Total Return: 0.11% (¬± 0.10%, p05 -0.07%, median 0.11%, p95 0.27%)\n",
      " Average Directional Accuracy: 51.60%\n",
      " Average Profitable Trades: 52.28%\n",
      " Average Final Capital: $10010.81 (¬± $10.36)\n",
      " Average #Trades: 8.00 | Avg Trade Return: 0.0149%\n",
      "========================================\n",
      "üßÆ Model: GPT-3.5 Regime-Sensitive\n",
      "Starting hyperparameter tuning over 1 configurations...\n",
      "Sampling with best hyper... defaultdict(<class 'dict'>, {'model': 'gpt-3.5-turbo-instruct', 'temp': 1.2, 'alpha': 0.8, 'beta': 0.5, 'basic': False, 'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=', ', bit_sep=' ', plus_sign='', minus_sign=' -', half_bin_correction=True, decimal_point='', missing_str=' Nan')}) \n",
      " with NLL inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 94/94 [04:25<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prediction too short 28 < 29, padded with last value\n",
      "\n",
      " ===== LLM Statistical Metrics (noiseless) =====\n",
      "RMSE: 775494191.680574\n",
      "MAE: 144006358.146464\n",
      "R¬≤: -1812931481694162846220288.0000\n",
      "\n",
      " ===== Strategy: threshold ‚Äî 1000 runs =====\n",
      " Average Total Return: 0.33% (¬± 0.08%, p05 0.20%, median 0.33%, p95 0.46%)\n",
      " Average Directional Accuracy: 51.17%\n",
      " Average Profitable Trades: 52.76%\n",
      " Average Final Capital: $10033.44 (¬± $8.19)\n",
      " Average #Trades: 12.24 | Avg Trade Return: 0.0320%\n",
      "\n",
      " ===== Strategy: relative ‚Äî 1000 runs =====\n",
      " Average Total Return: 0.17% (¬± 0.10%, p05 -0.00%, median 0.18%, p95 0.33%)\n",
      " Average Directional Accuracy: 51.16%\n",
      " Average Profitable Trades: 52.12%\n",
      " Average Final Capital: $10017.34 (¬± $10.36)\n",
      " Average #Trades: 14.00 | Avg Trade Return: 0.0153%\n",
      "\n",
      " ===== Strategy: top_quartile ‚Äî 1000 runs =====\n",
      " Average Total Return: 0.18% (¬± 0.08%, p05 0.06%, median 0.18%, p95 0.30%)\n",
      " Average Directional Accuracy: 51.13%\n",
      " Average Profitable Trades: 51.84%\n",
      " Average Final Capital: $10018.09 (¬± $7.60)\n",
      " Average #Trades: 8.00 | Avg Trade Return: 0.0239%\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# Test GPT-3.5 Model\n",
    "# ======================================\n",
    "\n",
    "print(\"\\n TESTING GPT-3.5 MODEL\")\n",
    "print(\"=\" * 50)\n",
    "gpt3_models = {'LLMTime GPT-3.5': gpt3_hypers, 'GPT-3.5 Regime-Sensitive': gpt3_regime_sensitive}\n",
    "all_gpt3_results = dict()\n",
    "\n",
    "for model_name, params in gpt3_models.items():\n",
    "    print(f\"üßÆ Model: {model_name}\")\n",
    "    all_gpt3_results[model_name] = predict_returns_with_trading(\n",
    "        splits, \n",
    "        model_type=\"llm\", \n",
    "        forecast_horizon=FORECAST_HORIZON, \n",
    "        hypers=params,\n",
    "        initial_capital=INITIAL_CAPITAL,\n",
    "        verbose=False)\n",
    "    print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89a7cb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TESTING GPT-4 MODEL\n",
      "==================================================\n",
      "üßÆ Model: LLMTime GPT-4\n",
      "Starting hyperparameter tuning over 1 configurations...\n",
      "Sampling with best hyper... defaultdict(<class 'dict'>, {'model': 'gpt-4', 'alpha': 0.3, 'basic': True, 'temp': 1.0, 'top_p': 0.8, 'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=', ', bit_sep='', plus_sign='', minus_sign='-', half_bin_correction=True, decimal_point='', missing_str=' Nan')}) \n",
      " with NLL inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                    | 0/94 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, params \u001b[38;5;129;01min\u001b[39;00m gpt4_models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müßÆ Model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m     all_gpt4_results[model_name] \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_returns_with_trading\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforecast_horizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFORECAST_HORIZON\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhypers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgpt4_hypers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitial_capital\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mINITIAL_CAPITAL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m40\u001b[39m)\n",
      "Cell \u001b[0;32mIn[21], line 55\u001b[0m, in \u001b[0;36mpredict_returns_with_trading\u001b[0;34m(train_data, model_type, forecast_horizon, hypers, initial_capital, strategies, monte_carlo_runs, noise_std, seed, verbose)\u001b[0m\n\u001b[1;32m     53\u001b[0m     preds_base \u001b[38;5;241m=\u001b[39m arima_forecast(data_history,data_true_forecast, forecast_horizon\u001b[38;5;241m=\u001b[39mforecast_horizon, hypers\u001b[38;5;241m=\u001b[39mhypers)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_type\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 55\u001b[0m     preds_base \u001b[38;5;241m=\u001b[39m \u001b[43mllm_forecast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_history\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_true_forecast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforecast_horizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforecast_horizon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhypers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type must be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marima\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mllm\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 35\u001b[0m, in \u001b[0;36mllm_forecast\u001b[0;34m(x, x_forecast, forecast_horizon, hypers)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hypers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m    \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing hypers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 35\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mget_autotuned_predictions_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_forecast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhypers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhypers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_predictions_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_llmtime_predictions_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     43\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m fc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(preds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m h), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fc\n",
      "File \u001b[0;32m~/TM/LLMinStockPrediction/models/validation_likelihood_tuning.py:120\u001b[0m, in \u001b[0;36mget_autotuned_predictions_data\u001b[0;34m(train, test, hypers, num_samples, get_predictions_fn, verbose, parallel, n_train, n_val)\u001b[0m\n\u001b[1;32m    118\u001b[0m     best_val_nll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSampling with best hyper... \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_hyper\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m with NLL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_val_nll\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 120\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mget_predictions_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbest_hyper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_hyper\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mconvert_to_dict(best_hyper)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/TM/LLMinStockPrediction/models/llmtime.py:229\u001b[0m, in \u001b[0;36mget_llmtime_predictions_data\u001b[0;34m(train, test, model, settings, num_samples, temp, alpha, beta, basic, parallel, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m completions_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 229\u001b[0m     preds, completions_list, input_strs \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompletion_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_strs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m     samples \u001b[38;5;241m=\u001b[39m [pd\u001b[38;5;241m.\u001b[39mDataFrame(preds[i], columns\u001b[38;5;241m=\u001b[39mtest[i]\u001b[38;5;241m.\u001b[39mindex) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(preds))]\n\u001b[1;32m    233\u001b[0m     medians \u001b[38;5;241m=\u001b[39m [sample\u001b[38;5;241m.\u001b[39mmedian(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m samples]\n",
      "File \u001b[0;32m~/TM/LLMinStockPrediction/models/llmtime.py:160\u001b[0m, in \u001b[0;36mgenerate_predictions\u001b[0;34m(completion_fn, input_strs, steps, settings, scalers, num_samples, temp, parallel, strict_handling, max_concurrent, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m         completions_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(tqdm(p\u001b[38;5;241m.\u001b[39mmap(complete, input_strs), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(input_strs)))\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     completions_list \u001b[38;5;241m=\u001b[39m [complete(input_str) \u001b[38;5;28;01mfor\u001b[39;00m input_str \u001b[38;5;129;01min\u001b[39;00m tqdm(input_strs)]\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompletion_to_pred\u001b[39m(completion, inv_transform): \n\u001b[1;32m    162\u001b[0m     deserialized \u001b[38;5;241m=\u001b[39m deserialize_str(completion, settings, ignore_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, steps\u001b[38;5;241m=\u001b[39msteps) \n",
      "File \u001b[0;32m~/TM/LLMinStockPrediction/models/llmtime.py:160\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    158\u001b[0m         completions_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(tqdm(p\u001b[38;5;241m.\u001b[39mmap(complete, input_strs), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(input_strs)))\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     completions_list \u001b[38;5;241m=\u001b[39m [\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_str\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m input_str \u001b[38;5;129;01min\u001b[39;00m tqdm(input_strs)]\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompletion_to_pred\u001b[39m(completion, inv_transform): \n\u001b[1;32m    162\u001b[0m     deserialized \u001b[38;5;241m=\u001b[39m deserialize_str(completion, settings, ignore_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, steps\u001b[38;5;241m=\u001b[39msteps) \n",
      "File \u001b[0;32m~/TM/LLMinStockPrediction/models/llmtime.py:155\u001b[0m, in \u001b[0;36mgenerate_predictions.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03mGenerate and process text completions from a language model for input time series.\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;124;03m        - input_strs (list of str): Serialized input strings.\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    154\u001b[0m completions_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 155\u001b[0m complete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mcompletion_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mSTEP_MULTIPLIER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parallel \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(input_strs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(\u001b[38;5;28mmin\u001b[39m(max_concurrent, \u001b[38;5;28mlen\u001b[39m(input_strs))) \u001b[38;5;28;01mas\u001b[39;00m p:\n",
      "File \u001b[0;32m~/TM/LLMinStockPrediction/models/gpt.py:66\u001b[0m, in \u001b[0;36mgpt_completion_fn\u001b[0;34m(model, input_str, steps, settings, num_samples, temp)\u001b[0m\n\u001b[1;32m     64\u001b[0m     chatgpt_sys_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful assistant that performs time series predictions. The user will provide a sequence and you will predict the remaining sequence. The sequence is represented by decimal strings separated by commas.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     65\u001b[0m     extra_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease continue the following sequence without producing any additional text. Do not say anything like \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe next terms in the sequence are\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, just return the numbers. Sequence:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 66\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mchatgpt_sys_message\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_input\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43minput_str\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_sep\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mavg_tokens_per_step\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [choice\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;28;01mfor\u001b[39;00m choice \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices]\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_stock_prediciton/lib/python3.9/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_stock_prediciton/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    139\u001b[0m ):\n\u001b[1;32m    140\u001b[0m     (\n\u001b[1;32m    141\u001b[0m         deployment_id,\n\u001b[1;32m    142\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    153\u001b[0m     )\n\u001b[0;32m--> 155\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_stock_prediciton/lib/python3.9/site-packages/openai/api_requestor.py:289\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    280\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    288\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m--> 289\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_raw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupplied_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_stock_prediciton/lib/python3.9/site-packages/openai/api_requestor.py:606\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    604\u001b[0m     _thread_context\u001b[38;5;241m.\u001b[39msession_create_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 606\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_thread_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mabs_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mTIMEOUT_SECS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_thread_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mTimeout(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest timed out: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_stock_prediciton/lib/python3.9/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_stock_prediciton/lib/python3.9/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_stock_prediciton/lib/python3.9/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_stock_prediciton/lib/python3.9/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_stock_prediciton/lib/python3.9/site-packages/urllib3/connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_stock_prediciton/lib/python3.9/site-packages/urllib3/connection.py:516\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    513\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_stock_prediciton/lib/python3.9/http/client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1377\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1379\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_stock_prediciton/lib/python3.9/http/client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_stock_prediciton/lib/python3.9/http/client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 281\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_stock_prediciton/lib/python3.9/socket.py:716\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 716\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    718\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_stock_prediciton/lib/python3.9/ssl.py:1275\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1272\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1273\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1274\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_stock_prediciton/lib/python3.9/ssl.py:1133\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# Test GPT-4 Model\n",
    "# ======================================\n",
    "\n",
    "print(\"\\n TESTING GPT-4 MODEL\")\n",
    "print(\"=\" * 50)\n",
    "gpt4_models = {'LLMTime GPT-4': gpt4_hypers, \n",
    "     'GPT-4 Volatility-Aware': gpt4_volatility_aware,\n",
    "     'GPT-4 Conservative':gpt4_conservative}\n",
    "all_gpt4_results = dict()\n",
    "\n",
    "for model_name, params in gpt4_models.items():\n",
    "    print(f\"üßÆ Model: {model_name}\")\n",
    "    all_gpt4_results[model_name] = predict_returns_with_trading(\n",
    "        splits, \n",
    "        model_type=\"llm\", \n",
    "        forecast_horizon=FORECAST_HORIZON, \n",
    "        hypers=gpt4_hypers,\n",
    "        initial_capital=INITIAL_CAPITAL,\n",
    "        verbose=False\n",
    "    )\n",
    "    print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddffb29-cd44-40b3-a6c9-c97f94c584bc",
   "metadata": {},
   "source": [
    "#### Discussion of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70675b0-3c11-4382-89a4-5b9a5254163c",
   "metadata": {},
   "source": [
    "For each model, the best-performing configuration is selected, with **Directional Accuracy used as the primary criterion** for evaluation and comparison. However, all models‚Äîregardless of configuration‚Äîproduced similar overall results, highlighting the **limited variation in performance across different setups**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40da95d1-6a1f-42c0-8f37-be7bd0cb1671",
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_results = all_arima_results[\"ARIMA\"]\n",
    "gpt3_results = all_gpt3_results[\"LLMTime GPT-3.5\"]\n",
    "gpt4_results = all_gpt4_results[\"GPT-4 Volatility-Aware\"]\n",
    "comparison_results = {\n",
    "    'arima': arima_results,\n",
    "    'gpt3': gpt3_results, \n",
    "    'gpt4': gpt4_results\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b573de",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = create_performance_summary_table(comparison_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5333eed4-6e7f-42b3-8d60-8ae853ec316e",
   "metadata": {},
   "source": [
    "In this comparison, the **statistical metrics** (RMSE, MAE, and R¬≤) are not the main focus, since the goal is **not to predict the exact return values**. They are added to complete the full analysis, however what matters most are the **Trading Protocol metrics**, especially the **Directional Accuracy**.\n",
    "\n",
    "##### üîç Observations\n",
    "\n",
    "Overall, the three models behave quite similarly, and **none delivers a strong predictive capability**. They all show **directional accuracy close to random** (around **55‚Äì62%**), meaning none of them consistently predicts the right direction much better than chance.  \n",
    "\n",
    "These results prove the statement the **difficulty of financial forecasting**, where even advanced models struggle to outperform random direction guessing.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f1227d-5a59-498e-a12c-fb6ee7ebd67d",
   "metadata": {},
   "source": [
    "#### Visualization of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025918aa-0e4f-422b-a885-e2a2b2bd323b",
   "metadata": {},
   "source": [
    "##### üìä Plot Predictions vs Actual Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963d84e8-7b17-4ec2-a2c4-d3800fefb46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(arima_results['actual']))\n",
    "print(len(arima_results['actual'][0]))\n",
    "print(len(gpt3_results['actual']))\n",
    "print(len(gpt3_results['actual'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9b1051-c10a-4cef-b6b9-556d6fc9e07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_vs_actual(comparison_results, forecast_horizon=FORECAST_HORIZON)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2587ebd6-3830-4172-8813-4fcd82a01b8a",
   "metadata": {},
   "source": [
    "In this project, it is **expected** that the models will not precisely match the actual return series values. The purpose of this plot is mainly to visualize the predicted versus actual returns and not to assess value accuracy. \n",
    "\n",
    "We can observe a **linear and smoothed trend** from the **ARIMA model**, which is consistent with its statistical and stationary assumptions. In contrast, **GPT-3.5** and **GPT-4** display a **more dynamic and nonlinear behavior**, producing sharper fluctuations and less stable trends.\n",
    "\n",
    "Despite the differences in predicted values, all models show a **similar level of directional understanding**, which is close to random performance. This emphasizes the inherent difficulty of forecasting stock returns providing only the historic time-series data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d23b03e-9a3f-4f3d-95d9-a1c95cb3a595",
   "metadata": {},
   "source": [
    "#### üí∞ Cumulative Trading Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee1dc94-09dd-4b59-aa2c-69b57ea002e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cumulative_returns_simulation(comparison_results, initial_capital=INITIAL_CAPITAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14efe057-94bd-45d9-b3ba-89c8ed6d7aaa",
   "metadata": {},
   "source": [
    "This plot shows the **cumulative portfolio value** over the 30-day trading horizon for different trading approaches:  \n",
    "**Buy & Hold**, **ARIMA-based trading**, **GPT-3.5 trading**, and **GPT-4 trading**.\n",
    "\n",
    "_Definition_:\n",
    "The **Buy & Hold** strategy (gray dashed line) represents a **baseline investor** who invests once at the beginning and holds the asset throughout the entire period without making any trades.  \n",
    "\n",
    "\n",
    "The LLM-based models (GPT-3.5 and GPT-4) show more active trading behavior, but their results are unstable and inconsistent, reflecting the randomness and noise in real market movements. The Buy & Hold strategy still performs better than all model-based approaches, which is common in stock forecasting.\n",
    "\n",
    "In the end, even with advanced models, predicting market returns doesn‚Äôt always lead to better trading results, highlighting just how unpredictable and challenging stock markets really are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267a93db-b0f8-4c05-b0f8-3b8af8671ba7",
   "metadata": {},
   "source": [
    "#### Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66272bf5-c894-4572-96c2-a3f1be42a0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(create_performance_summary_table(comparison_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d211ea7b-26f1-41ba-a248-4b6111301df3",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This project explored the application of Large Language Models (LLMs) for stock market prediction, specifically focusing on S&P 500 returns forecasting. The research compared traditional statistical methods (ARIMA) with modern LLM-based approaches (GPT-3.5 and GPT-4) using a evaluation framework that included statistical metrics, but focuses more on practical trading performance assessment.\n",
    "\n",
    "### üéØ **Key Findings**\n",
    "\n",
    "1. **Limited Predictive Performance Across All Models**\n",
    "   - All models demonstrated **directional accuracy close to random** (55-62%), indicating that none consistently outperformed chance in predicting market direction\n",
    "   - Statistical metrics (RMSE, MAE, R¬≤) showed poor fit across all approaches, confirming the challenging nature of financial time series prediction\n",
    "\n",
    "2. **Model Behavior Differences**\n",
    "   - **ARIMA** produced **linear and smoothed predictions**, consistent with its statistical assumptions and stationarity requirements\n",
    "   - **LLM models** (GPT-3.5 and GPT-4) exhibited **more dynamic and nonlinear behavior** with sharper fluctuations, potentially capturing complex patterns but failing to translate into superior accuracy\n",
    "   - Despite different prediction patterns, all models converged to similar **overall performance levels**\n",
    "\n",
    "### üîç **Implications for Financial Forecasting**\n",
    "\n",
    "The results reinforce the **Efficient Market Hypothesis** and highlight several critical insights:\n",
    "\n",
    "- **Market Complexity**: Even sophisticated models like GPT-4 struggle with the inherent randomness and complexity of financial markets\n",
    "- **Data Limitations**: Historical return patterns may not contain sufficient predictive signals for future performance\n",
    "- **Model Limitations**: Both statistical and deep learning approaches face challenges when applied to highly volatile, non-stationary financial data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7365dd81-76a4-4625-87f1-6eaadaaa65d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
